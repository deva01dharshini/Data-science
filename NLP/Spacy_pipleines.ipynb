{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy Language Processing Pipeline**"
      ],
      "metadata": {
        "id": "3iMHhi1oCEkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blank NLP Pipeline"
      ],
      "metadata": {
        "id": "SWXQ8o0aCPjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "oS5M8qXcCKnM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.blank('en')\n",
        "doc=nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxFj6sJWCX9i",
        "outputId": "ce6c1fd8-97b2-4010-ed8b-7504f5cf6d6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain\n",
            "america\n",
            "ate\n",
            "100\n",
            "$\n",
            "of\n",
            "samosa\n",
            ".\n",
            "Then\n",
            "he\n",
            "said\n",
            "I\n",
            "can\n",
            "do\n",
            "this\n",
            "all\n",
            "day\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCC_rbGTCyMq",
        "outputId": "26100350-2c8d-4df0-8bfe-65968bdaba5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Trained pipeline**"
      ],
      "metadata": {
        "id": "ojyAocQfDTPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_sm')\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2Hw0YrSC2ky",
        "outputId": "111257a1-1ed6-4a37-bddf-d77524d11d98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLTnAG5zDgdr",
        "outputId": "0c0a5237-8fab-459f-d9bb-4d1dbadda94f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x79a11acb2ce0>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x79a11acb23e0>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x79a11ac302e0>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x79a11ac1af00>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x79a11af3e740>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x79a11ac30270>)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")"
      ],
      "metadata": {
        "id": "eOI-6BzkDzKZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token,'|',spacy.explain(token.pos_),'|',token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_iAjScpD5Yo",
        "outputId": "353449da-af47-47a0-fbe5-33c0795f5ec3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain | proper noun | Captain\n",
            "america | proper noun | america\n",
            "ate | verb | eat\n",
            "100 | numeral | 100\n",
            "$ | numeral | $\n",
            "of | adposition | of\n",
            "samosa | proper noun | samosa\n",
            ". | punctuation | .\n",
            "Then | adverb | then\n",
            "he | pronoun | he\n",
            "said | verb | say\n",
            "I | pronoun | I\n",
            "can | auxiliary | can\n",
            "do | verb | do\n",
            "this | pronoun | this\n",
            "all | determiner | all\n",
            "day | noun | day\n",
            ". | punctuation | .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition**"
      ],
      "metadata": {
        "id": "QEFF2w9jEaqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "  print(ent.text,'|',ent.label_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neH1LfI-D8YA",
        "outputId": "4640c573-1470-4346-cd30-ece3a8c631ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc | ORG\n",
            "$45 billion | MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc,style='ent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "pqUioL8dEvlN",
        "outputId": "7bd8ff7f-ec14-4b0f-d345-e331a31c4de0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    Tesla Inc\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\\n</mark>\\n is going to acquire twitter for \\n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\\n    $45 billion\\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\\n</mark>\\n</div>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding component to a blank pipeline**"
      ],
      "metadata": {
        "id": "PuCjLAroHAMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_nlp=spacy.load('en_core_web_sm')\n"
      ],
      "metadata": {
        "id": "zwmzNpAuGSon"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.blank('en')\n",
        "nlp.add_pipe('ner',source=source_nlp)\n",
        "nlp.pipe_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNb5kuppHPsU",
        "outputId": "c09de918-0026-4b80-bc22-6176a74e98a0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ner']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "  print(ent.text,ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvWDEq2eHgMI",
        "outputId": "42ce2629-43cd-49d8-e1c4-e413d1a3c90a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc ORG\n",
            "$45 billion MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Examples**"
      ],
      "metadata": {
        "id": "_FFBX4my7VBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "NtqvGg3_770M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To extract all pronouns from the text"
      ],
      "metadata": {
        "id": "HDEg1Kea8PZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and\n",
        "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
        "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
        "'''\n",
        "doc=nlp(text)\n",
        "proper_noun=[]\n",
        "for token in doc:\n",
        "  if token.pos_=='PROPN':\n",
        "    proper_noun.append(token)\n",
        "proper_noun"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHfyCmR9Hvob",
        "outputId": "220d40fe-3dfd-4276-c39f-a1f8a2ab03fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Raju, Paris, London, Dubai, Rome, Mohan, Hyderabad]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting all Company names and Count of all company names"
      ],
      "metadata": {
        "id": "vuMcioaI_L-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in\n",
        "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel'''\n",
        "doc=nlp(text)\n",
        "all_company_names=[]\n",
        "for ent in doc.ents:\n",
        "  if ent.label_=='ORG':\n",
        "    all_company_names.append(ent)\n",
        "print(all_company_names)\n",
        "count=len(all_company_names)\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTg0z6lu7cq9",
        "outputId": "bd6d56c2-a78b-4dcf-afc4-302faa6a91a7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tesla, Walmart, Amazon, Microsoft, Google, Infosys, Reliance, HDFC Bank, Hindustan Unilever, Bharti]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}